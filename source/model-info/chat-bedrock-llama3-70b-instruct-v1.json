{
    "UseCase": "Chat",
    "ModelProviderName": "Bedrock",
    "ModelName": "meta.llama3-70b-instruct-v1:0",
    "AllowsStreaming": true,
    "Prompt": "{history}\n\n{input}",
    "MaxTemperature": "1",
    "DefaultTemperature": "0.5",
    "MinTemperature": "0",
    "DefaultStopSequences": [],
    "MemoryConfig": {
        "history": "history",
        "input": "input",
        "context": null,
        "ai_prefix": "AI",
        "human_prefix": "Human",
        "output": null
    },
    "MaxPromptSize": 15000,
    "MaxChatMessageSize": 15000
}