{
  "UseCase": "Chat",
  "ModelProviderName": "Bedrock",
  "ModelName": "inference-profile",
  "AllowsStreaming": true,
  "Prompt": "{history}\n\n{input}",
  "MaxTemperature": "1",
  "DefaultTemperature": "0.5",
  "MinTemperature": "0",
  "DefaultStopSequences": [],
  "MemoryConfig": {
    "history": "history",
    "input": "input",
    "context": null,
    "ai_prefix": "AI",
    "human_prefix": "Human",
    "output": null
  },
  "MaxPromptSize": 375000,
  "MaxChatMessageSize": 375000
}